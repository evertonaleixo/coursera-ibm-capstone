{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a href=\"http://cocl.us/pytorch_link_top\">\n    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n</a> \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>Prebuilt Datasets and Transforms</h1> \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>Objective</h2><ul><li> How to use MNIST prebuilt dataset in pytorch.</li></ul> \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>Table of Contents</h2>\n<p>In this lab, you will use a prebuilt dataset and then use some prebuilt dataset transforms.</p>\n<ul>\n    <li><a href=\"#Prebuilt_Dataset\">Prebuilt Datasets</a></li>\n    <li><a href=\"#Torchvision\">Torchvision Transforms</a></li>\n</ul>\n<p>Estimated Time Needed: <strong>10 min</strong></p>\n\n<hr>\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>Preparation</h2>\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "#!conda install pytorch torchvision -c pytorch"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "<torch._C.Generator at 0x7fe6c44e4210>"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# These are the libraries will be used for this lab.\n\nimport torch \nimport matplotlib.pylab as plt\nimport numpy as np\ntorch.manual_seed(0)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This is the function for displaying images.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "# Show data by diagram\n\ndef show_data(data_sample, shape = (28, 28)):\n    plt.imshow(data_sample[0].numpy().reshape(shape), cmap='gray')\n    plt.title('y = ' + str(data_sample[1]))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"Prebuilt_Dataset\">Prebuilt Datasets</h2> \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "You will focus on the following libraries: \n"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "# Run the command below when you do not have torchvision installed\n# !conda install -y torchvision\n\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can import a prebuilt dataset. In this case, use MNIST. You'll work with several of these parameters later by placing a transform object in the argument <code>transform</code>.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a41365b4b97049baa1988b2a776f5fa8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nExtracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e1bc7d02085c4fa9a1bfc83efcdd2c59",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nExtracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "152e9f0fd2624c7799eef1828fd7dd85",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nExtracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b1b183bd2b054aa2b7f5b4e51a11ba67",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nExtracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\nProcessing...\nDone!\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629431274/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
                }
            ],
            "source": "# Import the prebuilt dataset into variable dataset\n\ndataset = dsets.MNIST(\n    root = './data', \n    train = False, \n    download = True, \n    transform = transforms.ToTensor()\n)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Each element of the dataset object contains a tuple. Let us see whether the first element in the dataset is a tuple and what is in it.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Type of the first element:  <class 'tuple'>\nThe length of the tuple:  2\nThe shape of the first element in the tuple:  torch.Size([1, 28, 28])\nThe type of the first element in the tuple <class 'torch.Tensor'>\nThe second element in the tuple:  7\nThe type of the second element in the tuple:  <class 'int'>\nAs the result, the structure of the first element in the dataset is (tensor([1, 28, 28]), tensor(7)).\n"
                }
            ],
            "source": "# Examine whether the elements in dataset MNIST are tuples, and what is in the tuple?\n\nprint(\"Type of the first element: \", type(dataset[0]))\nprint(\"The length of the tuple: \", len(dataset[0]))\nprint(\"The shape of the first element in the tuple: \", dataset[0][0].shape)\nprint(\"The type of the first element in the tuple\", type(dataset[0][0]))\nprint(\"The second element in the tuple: \", dataset[0][1])\nprint(\"The type of the second element in the tuple: \", type(dataset[0][1]))\nprint(\"As the result, the structure of the first element in the dataset is (tensor([1, 28, 28]), tensor(7)).\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As shown in the output, the first element in the tuple is a cuboid tensor. As you can see, there is a dimension with only size 1, so basically, it is a rectangular tensor.<br>\nThe second element in the tuple is a number tensor, which indicate the real number the image shows. As the second element in the tuple is <code>tensor(7)</code>, the image should show a hand-written 7.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let us plot the first element in the dataset:\n"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "cannot reshape array of size 400 into shape (28,28)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-14-01ed8c76bb05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the first element in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m<ipython-input-13-be09ffaf80eb>\u001b[0m in \u001b[0;36mshow_data\u001b[0;34m(data_sample, shape)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 400 into shape (28,28)"
                    ]
                }
            ],
            "source": "# Plot the first element in the dataset\n\nshow_data(dataset[0])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As we can see, it is a 7.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Plot the second sample:   \n"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "'int' object has no attribute 'item'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-9-e1d505efaf9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the second element in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m<ipython-input-4-b5f90e634108>\u001b[0m in \u001b[0;36mshow_data\u001b[0;34m(data_sample, shape)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'item'"
                    ]
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "# Plot the second element in the dataset\n\nshow_data(dataset[1])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"Torchvision\"> Torchvision Transforms  </h2> \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can apply some image transform functions on the MNIST dataset.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As an example, the images in the MNIST dataset can be cropped and converted to a tensor. We can use <code>transform.Compose</code> we learned from the previous lab to combine the two transform functions.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The shape of the first element in the first tuple:  torch.Size([1, 20, 20])\n"
                }
            ],
            "source": "# Combine two transforms: crop and convert to tensor. Apply the compose to MNIST dataset\n\ncroptensor_data_transform = transforms.Compose([transforms.CenterCrop(20), transforms.ToTensor()])\ndataset = dsets.MNIST(root = './data', train = False, download = True, transform = croptensor_data_transform)\nprint(\"The shape of the first element in the first tuple: \", dataset[0][0].shape)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can see the image is now 20 x 20 instead of 28 x 28.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let us plot the first image again. Notice that the black space around the <b>7</b> become less apparent.\n"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "'int' object has no attribute 'item'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-11-fc2e939938bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the first element in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m<ipython-input-4-b5f90e634108>\u001b[0m in \u001b[0;36mshow_data\u001b[0;34m(data_sample, shape)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'item'"
                    ]
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "# Plot the first element in the dataset\n\nshow_data(dataset[0],shape = (20, 20))"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "'int' object has no attribute 'item'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-12-f96c1b437f78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the second element in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m<ipython-input-4-b5f90e634108>\u001b[0m in \u001b[0;36mshow_data\u001b[0;34m(data_sample, shape)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'item'"
                    ]
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "# Plot the second element in the dataset\n\nshow_data(dataset[1],shape = (20, 20))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In the below example, we horizontally flip the image, and then convert it to a tensor. Use <code>transforms.Compose()</code> to combine these two transform functions. Plot the flipped image.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Construct the compose. Apply it on MNIST dataset. Plot the image out.\n\nfliptensor_data_transform = transforms.Compose([transforms.RandomHorizontalFlip(p = 1),transforms.ToTensor()])\ndataset = dsets.MNIST(root = './data', train = False, download = True, transform = fliptensor_data_transform)\nshow_data(dataset[1])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h3>Practice</h3>\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Try to use the <code>RandomVerticalFlip</code> (vertically flip the image) with horizontally flip and convert to tensor as a compose. Apply the compose on image. Use <code>show_data()</code> to plot the second image (the image as <b>2</b>).\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Practice: Combine vertical flip, horizontal flip and convert to tensor as a compose. Apply the compose on image. Then plot the image\n\n# Type your code here\n\nmy_data_transform = transforms.Compose([transforms.RandomVerticalFlip(p = 1), transforms.RandomHorizontalFlip(p = 1), transforms.ToTensor()])\ndataset = dsets.MNIST(root = './data', train = False, download = True, transform = my_data_transform)\nshow_data(dataset[1])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Double-click **here** for the solution.\n\n<!-- \nmy_data_transform = transforms.Compose([transforms.RandomVerticalFlip(p = 1), transforms.RandomHorizontalFlip(p = 1), transforms.ToTensor()])\ndataset = dsets.MNIST(root = './data', train = False, download = True, transform = my_data_transform)\nshow_data(dataset[1])\n -->\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a href=\"http://cocl.us/pytorch_link_bottom\">\n    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n</a>\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>About the Authors:</h2> \n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a> \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n| 2020-09-21        | 2.0     | Shubham    | Migrated Lab to Markdown and added to course repo in GitLab |\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<hr>\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Copyright \u00a9 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}